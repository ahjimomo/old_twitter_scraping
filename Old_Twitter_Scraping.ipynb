{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed6bb33",
   "metadata": {},
   "source": [
    "### Script to scrape old twitter posts older than 1-week\n",
    "\n",
    "- Date Created: 5 July 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc885429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install snscrape\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c34771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install tweepy\n",
    "#!{sys.executable} -m pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da78e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f801a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your own credentials here.\n",
    "consumer_key = \"***\"\n",
    "consumer_secret = \"***\"\n",
    "access_token = \"***\"\n",
    "access_token_secret = \"***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc322584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authorize & link API with your twitter Dev\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0674930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sns scraper for twitter\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573fee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update your query keyword, start date, end date, file name to be saved, number of tweets to scrape\n",
    "keyword = \"BlueSG\"\n",
    "start_dt = \"2022-01-01\"\n",
    "end_dt = \"2022-04-07\"\n",
    "file_name = \"BlueSG_tweets_2.csv\"\n",
    "num_tweets_to_scrape = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd070d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a csv in which you want to store the data.\n",
    "csvFile = open(file_name, 'a') \n",
    "csvWriter = csv.writer(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb89133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-06 03:27:50+00:00\n",
      "2022-04-06 03:27:49+00:00\n",
      "2022-04-06 03:23:26+00:00\n",
      "2022-04-05 04:57:01+00:00\n",
      "2022-04-04 08:28:44+00:00\n",
      "2022-04-04 06:23:26+00:00\n",
      "2022-04-03 17:46:20+00:00\n",
      "2022-04-03 13:11:18+00:00\n",
      "2022-04-02 13:47:35+00:00\n",
      "2022-04-02 04:53:18+00:00\n",
      "2022-04-01 23:52:29+00:00\n",
      "2022-03-28 15:37:31+00:00\n",
      "2022-03-27 10:07:23+00:00\n",
      "2022-03-27 08:26:16+00:00\n",
      "2022-03-24 01:28:05+00:00\n",
      "2022-03-22 09:29:15+00:00\n",
      "2022-03-21 15:27:15+00:00\n",
      "2022-03-21 11:35:28+00:00\n",
      "2022-03-21 04:11:03+00:00\n",
      "2022-03-21 04:11:03+00:00\n",
      "2022-03-14 16:22:38+00:00\n",
      "2022-03-14 04:55:31+00:00\n",
      "2022-03-13 09:59:47+00:00\n",
      "2022-03-10 15:56:01+00:00\n",
      "2022-03-08 10:02:28+00:00\n",
      "2022-03-07 15:22:15+00:00\n",
      "2022-03-07 05:05:34+00:00\n",
      "2022-03-07 04:48:46+00:00\n",
      "2022-03-07 04:29:43+00:00\n",
      "2022-03-07 04:27:48+00:00\n",
      "2022-03-07 04:26:54+00:00\n",
      "2022-03-07 03:09:56+00:00\n",
      "2022-03-03 05:19:57+00:00\n",
      "2022-03-02 11:25:37+00:00\n",
      "2022-02-28 13:19:29+00:00\n",
      "2022-02-27 16:28:33+00:00\n",
      "2022-02-26 12:02:00+00:00\n",
      "2022-02-26 09:20:55+00:00\n",
      "2022-02-26 08:57:54+00:00\n",
      "2022-02-26 08:52:04+00:00\n",
      "2022-02-26 08:19:27+00:00\n",
      "2022-02-25 06:45:20+00:00\n",
      "2022-02-20 12:26:00+00:00\n",
      "2022-02-20 02:48:36+00:00\n",
      "2022-02-18 04:54:23+00:00\n",
      "2022-02-13 03:37:55+00:00\n",
      "2022-02-06 13:44:12+00:00\n",
      "2022-02-05 12:35:09+00:00\n",
      "2022-02-05 10:33:38+00:00\n",
      "2022-02-03 12:39:54+00:00\n",
      "2022-02-03 05:01:24+00:00\n",
      "2022-02-01 17:12:02+00:00\n",
      "2022-01-31 10:55:41+00:00\n",
      "2022-01-31 05:29:53+00:00\n",
      "2022-01-31 04:48:20+00:00\n",
      "2022-01-30 17:03:04+00:00\n",
      "2022-01-30 11:29:17+00:00\n",
      "2022-01-29 00:13:08+00:00\n",
      "2022-01-25 14:50:37+00:00\n",
      "2022-01-24 17:21:59+00:00\n",
      "2022-01-24 12:32:27+00:00\n",
      "2022-01-22 09:27:38+00:00\n",
      "2022-01-21 17:28:47+00:00\n",
      "2022-01-21 13:24:58+00:00\n",
      "2022-01-17 13:11:34+00:00\n",
      "2022-01-13 11:51:12+00:00\n",
      "2022-01-13 05:00:20+00:00\n",
      "2022-01-11 10:49:56+00:00\n",
      "2022-01-07 15:47:38+00:00\n",
      "2022-01-05 10:54:11+00:00\n"
     ]
    }
   ],
   "source": [
    "# Iterate twitter and scrape tweets based on keyword\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(keyword + \" since:\" + start_dt + \" until:\" + end_dt).get_items()) :\n",
    "        if i > num_tweets_to_scrape :\n",
    "            break\n",
    "        print(tweet.date) # To confirm scraping is performed\n",
    "        \n",
    "        csvWriter.writerow([tweet.date, tweet.content.encode(\"utf-8\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05498be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close File\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa49a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and rename columns\n",
    "df = pd.read_csv(file_name, header = None)\n",
    "df.columns = [\"Date\", \"Tweets\"]\n",
    "df.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0b71b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of tweets scraped\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dfd3c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-06 03:27:50+00:00</td>\n",
       "      <td>b'people use blueSG here as portable motel hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-06 03:27:49+00:00</td>\n",
       "      <td>b'anyone in WA wanna lend me car :D i have 0 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-06 03:23:26+00:00</td>\n",
       "      <td>b'BlueSG car spotted in Woodlands Checkpoint -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-05 04:57:01+00:00</td>\n",
       "      <td>b\"I wouldn't be caught dead driving a bluesg\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-04 08:28:44+00:00</td>\n",
       "      <td>b'yoongi i got drivers license but no car leh....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  \\\n",
       "0  2022-04-06 03:27:50+00:00   \n",
       "1  2022-04-06 03:27:49+00:00   \n",
       "2  2022-04-06 03:23:26+00:00   \n",
       "3  2022-04-05 04:57:01+00:00   \n",
       "4  2022-04-04 08:28:44+00:00   \n",
       "\n",
       "                                              Tweets  \n",
       "0  b'people use blueSG here as portable motel hel...  \n",
       "1  b'anyone in WA wanna lend me car :D i have 0 a...  \n",
       "2  b'BlueSG car spotted in Woodlands Checkpoint -...  \n",
       "3      b\"I wouldn't be caught dead driving a bluesg\"  \n",
       "4  b'yoongi i got drivers license but no car leh....  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc07df",
   "metadata": {},
   "source": [
    "The output file in csv. format is now saved in the same file location with the script.\n",
    "\n",
    "There should be two (2) columns, first consisting of the date of tweet and the second consisting of the tweet itself. You may work with the document to clean/analyze accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
